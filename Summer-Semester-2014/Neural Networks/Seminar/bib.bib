% This file was created with JabRef 2.7b.
% Encoding: UTF-8


@incollection{SocherEtAl2013,
title = {{Parsing With Compositional Vector Grammars}},
author = {Richard Socher and John Bauer and Christopher D. Manning and Andrew Y. Ng},
booktitle = {{ACL}},
year = {2013}
}

@book{Chapman1987,
  added-at = {2011-04-12T00:00:00.000+0200},
  author = {Chapman, Nigel P.},
  biburl = {http://www.bibsonomy.org/bibtex/2c7ff66cb52890a6bd3a4be938dc4c755/dblp},
  interhash = {061bc278e87bb8bf80b1938c029a8866},
  intrahash = {c7ff66cb52890a6bd3a4be938dc4c755},
  isbn = {978-0-521-30413-9},
  keywords = {dblp},
  pages = {I-VIII, 1-228},
  publisher = {Cambridge University Press},
  timestamp = {2011-04-12T00:00:00.000+0200},
  title = {LR parsing - theory and practice.},
  year = 1987
}


@inproceedings{Charniak2005,
 author = {Charniak, Eugene and Johnson, Mark},
 title = {Coarse-to-fine N-best Parsing and MaxEnt Discriminative Reranking},
 booktitle = {Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics},
 series = {ACL '05},
 year = {2005},
 location = {Ann Arbor, Michigan},
 pages = {173--180},
 numpages = {8},
 url = {http://dx.doi.org/10.3115/1219840.1219862},
 doi = {10.3115/1219840.1219862},
 acmid = {1219862},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
}

@MISC{Krishnamurthy,
    author = {Jayant Krishnamurthy and Tom M. Mitchell},
    title = {Vector Space Semantic Parsing: A Framework for Compositional Vector Space Models},
    year = {}
}

@INPROCEEDINGS{Socher13,
    author = {Richard Socher and John Bauer and Christopher D. Manning and Andrew Y. Ng},
    title = {Parsing With Compositional Vector Grammars},
    booktitle = {In Proceedings of the ACL conference},
    year = {2013}
}

@article{Turney2010,
  author    = {Peter D. Turney and
               Patrick Pantel},
  title     = {From Frequency to Meaning: Vector Space Models of Semantics},
  journal   = {CoRR},
  volume    = {abs/1003.1141},
  year      = {2010},
  ee        = {http://arxiv.org/abs/1003.1141},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@MISC{Menchetti05,
    author = {Sauro Menchetti and Fabrizio Costa and Paolo Frasconi and Massimiliano Pontil},
    title = {Wide Coverage Natural Language Processing Using Kernel Methods and Neural Networks for Structured Data},
    year = {2005}
}

@MISC{Sleator91,
    author = {Daniel D. Sleator and Davy Temperley},
    title = {Parsing English with a Link Grammar},
    year = {1991}
}

@INPROCEEDINGS{Henderson03,
    author = {James Henderson},
    title = {Neural Network Probability Estimation for Broad Coverage Parsing},
    booktitle = {IN PROCEEDINGS OF THE 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2003},
    year = {2003},
    pages = {131--138},
    publisher = {}
}

@MISC{Socher_parsingnatural,
    author = {Richard Socher and Cliff Chiung-yu Lin and Andrew Y. Ng and Christopher D. Manning},
    title = {Parsing Natural Scenes and Natural Language with Recursive Neural Networks},
    year = {}
}

@article{Brown1992,
 author = {Brown, Peter F. and deSouza, Peter V. and Mercer, Robert L. and Pietra, Vincent J. Della and Lai, Jenifer C.},
 title = {Class-based N-gram Models of Natural Language},
 journal = {Comput. Linguist.},
 issue_date = {December 1992},
 volume = {18},
 number = {4},
 month = dec,
 year = {1992},
 issn = {0891-2017},
 pages = {467--479},
 numpages = {13},
 url = {http://dl.acm.org/citation.cfm?id=176313.176316},
 acmid = {176316},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@inproceedings{McClosky2006,
 author = {McClosky, David and Charniak, Eugene and Johnson, Mark},
 title = {Effective Self-training for Parsing},
 booktitle = {Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics},
 series = {HLT-NAACL '06},
 year = {2006},
 location = {New York, New York},
 pages = {152--159},
 numpages = {8},
 url = {http://dx.doi.org/10.3115/1220835.1220855},
 doi = {10.3115/1220835.1220855},
 acmid = {1220855},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
}

@article{Bowman13,
  author    = {Samuel R. Bowman},
  title     = {Can recursive neural tensor networks learn logical reasoning?},
  journal   = {CoRR},
  volume    = {abs/1312.6192},
  year      = {2013},
  ee        = {http://arxiv.org/abs/1312.6192},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@ARTICLE{Bengio-2009,
  author = {Bengio, Yoshua},
  title = {Learning deep architectures for {AI}},
  journal = {Foundations and Trends in Machine Learning},
  year = {2009},
  volume = {2},
  pages = {1--127},
  number = {1},
  note = {Also published as a book. Now Publishers, 2009.},
  abstract = {Theoretical results suggest that in order to learn the kind of complicated
	functions that can represent high-level abstractions (e.g. in vision,
	language, and other AI-level tasks), one may need {\insist deep architectures}.
	Deep architectures are composed of multiple levels of non-linear
	operations, such as in neural nets with many hidden layers or in
	complicated propositional formulae re-using many sub-formulae. Searching
	the parameter space of deep architectures is a difficult task, but
	learning algorithms such as those for Deep Belief Networks have recently
	been proposed to tackle this problem with notable success, beating
	the state-of-the-art in certain areas. This paper discusses the motivations
	and principles regarding learning algorithms for deep architectures,
	in particular those exploiting as building blocks unsupervised learning
	of single-layer models such as Restricted Boltzmann Machines, used
	to construct deeper models such as Deep Belief Networks.},
  doi = {10.1561/2200000006}
}

@inproceedings{HintonSejnowski83,
  added-at = {2008-09-16T23:39:07.000+0200},
  address = {Washington, DC},
  author = {Hinton, G. E. and Sejnowski, T. J.},
  biburl = {http://www.bibsonomy.org/bibtex/28d476b7882c2b3d837b76fd0bdb79fcb/brian.mingus},
  booktitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern
	Recognition},
  description = {CCNLab BibTeX},
  interhash = {5c61deeac4b02147602ac254eb6d048d},
  intrahash = {8d476b7882c2b3d837b76fd0bdb79fcb},
  key = {Hinton and Sejnowski},
  keywords = {nnets},
  timestamp = {2008-09-16T23:39:07.000+0200},
  title = {Optimal Perceptual Inference},
  year = 1983
}

@ARTICLE{Grainger2008,
  author = {Jonathan Grainger,Arnaud Rey, Stéphane Dufau},
  title = {Letter perception: from pixels to pandemonium},
  journal = {Trends in cognitive sciences},
  year = {2008},
  volume = {12},
  doi = {10.1016/j.tics.2008.06.006}
}

@book{minsky69perceptrons,
  added-at = {2008-05-16T13:57:01.000+0200},
  address = {Cambridge, MA, USA},
  author = {Minsky, Marvin and Papert, Seymour},
  biburl = {http://www.bibsonomy.org/bibtex/206a5a6751b3e61408455fca2ed8d87fc/sb3000},
  description = {: mf : blob : » bibtex},
  interhash = {d80d4948a422623047f1b800272c0389},
  intrahash = {06a5a6751b3e61408455fca2ed8d87fc},
  keywords = {linear-classification neural-networks seminal},
  publisher = {MIT Press},
  timestamp = {2008-05-16T13:57:01.000+0200},
  title = {Perceptrons: An Introduction to Computational Geometry},
  year = 1969
}

@article{Hubel1959,
    author = {HUBEL, D. H. and WIESEL, T. N.},
    citeulike-article-id = {2709722},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/14403679},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=14403679},
    issn = {0022-3751},
    journal = {The Journal of physiology},
    keywords = {electrophysiology, rate-code, visual},
    month = oct,
    pages = {574--591},
    pmid = {14403679},
    posted-at = {2009-04-24 17:49:47},
    priority = {4},
    title = {{Receptive fields of single neurones in the cat's striate cortex.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/14403679},
    volume = {148},
    year = {1959}
}


@inproceedings{Selfridge1958,
    address = {London},
    author = {Selfridge, O. G.},
    booktitle = {Proceedings of a Symposium Held at the National Physical Laboratory},
    citeulike-article-id = {795261},
    keywords = {lsb},
    month = nov,
    pages = {513--526},
    posted-at = {2006-08-10 13:54:09},
    priority = {2},
    publisher = {HMSO},
    title = {{Pandemonium: a paradigm for learning in Mechanisation of Thought Processes}},
    year = {1958}
}

@article{Fukushima1988,
title = "Neocognitron: A hierarchical neural network capable of visual pattern recognition ",
journal = "Neural Networks ",
volume = "1",
number = "2",
pages = "119 - 130",
year = "1988",
note = "",
issn = "0893-6080",
doi = "http://dx.doi.org/10.1016/0893-6080(88)90014-7",
url = "http://www.sciencedirect.com/science/article/pii/0893608088900147",
author = "Kunihiko Fukushima"
}

@ARTICLE{FukushimaM82,
  author = {Kunihiko Fukushima and Sei Miyake},
  title = {Neocognitron: A new algorithm for pattern recognition tolerant of
	deformations and shifts in position},
  journal = {Pattern Recognition},
  year = {1982},
  volume = {15},
  pages = {455-469},
  number = {6},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://dx.doi.org/10.1016/0031-3203(82)90024-3}
}

@ARTICLE{Hinton:2007,
  author = {Hinton, Geoffrey E.},
  title = {Learning multiple layers of representation},
  journal = {Trends in Cognitive Sciences},
  year = {2007},
  volume = {11},
  pages = {428-434},
  abstract = {To achieve its impressive performance in tasks such as speech perception
	or object recognition, the brain extracts multiple levels of representation
	from the sensory input. Backpropagation was the first computationally
	efficient model of how neural networks could learn multiple layers
	of representation, but it required labeled training data and it did
	not work well in deep networks. The limitations of backpropagation
	learning can now be overcome by using multilayer neural networks
	that contain top-down connections and training them to generate sensory
	data rather than to classify it. Learning multilayer generative models
	might seem difficult, but a recent discovery makes it easy to learn
	nonlinear distributed representations one layer at a time.},
  added-at = {2009-06-26T15:25:19.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/2e04a4837f839f9de31d84fd0a0896798/butz},
  description = {diverse cognitive systems bib},
  interhash = {6b17388236cbabbcdd76f466b0ce22a3},
  intrahash = {e04a4837f839f9de31d84fd0a0896798},
  keywords = {imported},
  owner = {butz},
  timestamp = {2009-06-26T15:25:19.000+0200}
}

@ARTICLE{HintonSalakhutdinov2006b,
  author = {Hinton, G E and Salakhutdinov, R R},
  title = {Reducing the dimensionality of data with neural networks},
  journal = {Science},
  year = {2006},
  volume = {313},
  pages = {504-507},
  number = {5786},
  month = Jul,
  abstract = {High-dimensional data can be converted to low-dimensional codes by
	training a multilayer neural network with a small central layer to
	reconstruct high-dimensional input vectors. Gradient descent can
	be used for fine-tuning the weights in such "autoencoder" networks,
	but this works well only if the initial weights are close to a good
	solution. We describe an effective way of initializing the weights
	that allows deep autoencoder networks to learn low-dimensional codes
	that work much better than principal components analysis as a tool
	to reduce the dimensionality of data.},
  added-at = {2008-07-15T10:05:18.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/2135bbce97b449ddf5fca7be88102b53c/tmalsburg},
  description = {Reducing the dimensionality of data with neural ne...[Science. 2006]
	- PubMed Result},
  doi = {10.1126/science.1127647},
  interhash = {019918b82518b74f443a22dc58a0117f},
  intrahash = {135bbce97b449ddf5fca7be88102b53c},
  keywords = {dimensionalityreduction neuralnetworks parameterestimation},
  pmid = {16873662},
  timestamp = {2008-07-15T10:05:18.000+0200},
  url = {http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=16873662&cmd=showdetailview&indexed=google}
}


@article{Hinton2006D,
 author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
 title = {A Fast Learning Algorithm for Deep Belief Nets},
 journal = {Neural Comput.},
 issue_date = {July 2006},
 volume = {18},
 number = {7},
 month = jul,
 year = {2006},
 issn = {0899-7667},
 pages = {1527--1554},
 numpages = {28},
 url = {http://dx.doi.org/10.1162/neco.2006.18.7.1527},
 doi = {10.1162/neco.2006.18.7.1527},
 acmid = {1161605},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@BOOK{Leunen:Scholars:92,
  title = {A Handbook for Scholars},
  publisher = {Oxford University Press},
  year = {1992},
  author = {M.-C. van Leunen}
}

@incollection{Hinton1986,
 author = {Hinton, G. E. and Sejnowski, T. J.},
 chapter = {Learning and Relearning in Boltzmann Machines},
 title = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1},
 editor = {Rumelhart, David E. and McClelland, James L. and PDP Research Group, CORPORATE},
 year = {1986},
 isbn = {0-262-68053-X},
 pages = {282--317},
 numpages = {36},
 url = {http://dl.acm.org/citation.cfm?id=104279.104291},
 acmid = {104291},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 