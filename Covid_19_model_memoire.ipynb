{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_19_model_memoire.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnanpc/IAS_Materials/blob/master/Covid_19_model_memoire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPS1yFt8w29N",
        "colab_type": "text"
      },
      "source": [
        "# Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIqi5wKtxAzV",
        "colab_type": "text"
      },
      "source": [
        "readme\n",
        "lstmcorona\n",
        "This is LSTM to predict the growth of COVID-19 pandemics\n",
        "The link of paper : https://arxiv.org/pdf/2005.04809.pdf\n",
        "\n",
        "Before using please download the dataset here:\n",
        "https://github.com/datasets/covid-19/tree/master/data\n",
        "\n",
        "Please modify the data pre-processing by yourself, for example if the duration of each sample is more than 100 days, you should modify the \"split_sequences\" function inside the code such that the proportion of input and label is around 75:25 or 70:30\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOG-ST1WYuV2",
        "colab_type": "code",
        "outputId": "a486d87d-6de8-4523-cef4-11f2dae7a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "from scipy.interpolate import UnivariateSpline  \n",
        "import pickle\n",
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTk-9gPjY5ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MV_LSTM(torch.nn.Module):\n",
        "    def __init__(self,n_features,seq_length):\n",
        "        super(MV_LSTM, self).__init__()\n",
        "        self.n_features = n_features\n",
        "        self.seq_len = seq_length\n",
        "        self.n_hidden = 30 # number of hidden states\n",
        "        self.n_layers = 4 # number of LSTM layers (stacked)\n",
        "        self.dropout = nn.Dropout(0.1) \n",
        "\n",
        "        self.l_lstm = torch.nn.LSTM(input_size = n_features, \n",
        "                                 hidden_size = self.n_hidden,\n",
        "                                 num_layers = self.n_layers, \n",
        "                                 batch_first = True\n",
        "                                 )\n",
        "        # according to pytorch docs LSTM output is \n",
        "        # (batch_size,seq_len, num_directions * hidden_size)\n",
        "        # when considering batch_first = True\n",
        "        self.l_linear = torch.nn.Linear(self.n_hidden*self.seq_len, 100)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "     \n",
        "        \n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # even with batch_first = True this remains same as docs\n",
        "        hidden_state = torch.zeros(self.n_layers,batch_size,self.n_hidden).cuda()\n",
        "        cell_state = torch.zeros(self.n_layers,batch_size,self.n_hidden).cuda()\n",
        "        self.hidden = (hidden_state, cell_state)\n",
        "\n",
        "\n",
        "    def forward(self, x):        \n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        lstm_out, self.hidden = self.l_lstm(x,self.hidden)\n",
        "        #lstm_out, self.hidden = self.l_lstm(x)\n",
        "        \n",
        "        # lstm_out(with batch_first = True) is \n",
        "        # (batch_size,seq_len,num_directions * hidden_size)\n",
        "        # for following linear layer we want to keep batch_size dimension and merge rest       \n",
        "        # .contiguous() -> solves tensor compatibility error\n",
        "        x = lstm_out.contiguous().view(batch_size,-1)\n",
        "        return self.sigmoid(self.l_linear(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrax9Sa8ZBg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    \n",
        "    for i in range(0,len(sequences),100):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if i!=0 and end_ix > len(sequences):\n",
        "            break\n",
        "        \n",
        "        sequences[i:end_ix,0]=np.insert(np.diff(sequences[i:end_ix,0]),0,0)\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix-30], sequences[end_ix-30:end_ix]\n",
        "        \n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bl4q-RPZHev",
        "colab_type": "code",
        "outputId": "7474c096-3293-495f-afc3-fb4ca3c1203e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "#read training data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasets/covid-19/master/data/time-series-19-covid-combined.csv', skiprows=1)\n",
        "df.head()\n",
        "df.info()\n",
        "df.columns = ['day','country', 'territory', 'lat','long','confirmed','recovered','deaths']\n",
        "\n",
        "is_china =  (df['country']=='China')\n",
        "\n",
        "#read testing data\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/datasets/covid-19/master/data/time-series-19-covid-combined.csv', skiprows=1)\n",
        "df2.head()\n",
        "df2.info()\n",
        "df2.columns = ['day','country', 'territory', 'lat','long','confirmed','recovered','deaths']\n",
        "\n",
        "is_indonesia =  (df2['country']=='Indonesia')\n",
        "\n",
        "#training data filtering\n",
        "data=df[df.country.isin(['China','Germany','Australia','Brazil','US','Belgium','Spain','Italy','UK','France','Japan','Malaysia','Vietnam','Iran','UEA','Singapore','Thailand','Korea, South','Japan','Iran','Netherlands','Russia','Chile','India','Greece','Mexico','Mongolia','Philippines','New Zealand','South Africa','Botswana','Uruguay','Paraguay','Madagascar','Peru', 'Portugal', 'Denmark','Hungary','Kenya','Ireland','Israel','Norway','Mauritius','Rwanda','Iceland','Kazakhstan','Switzerland','Cyprus','Zimbabwe'])][['confirmed','lat','long','recovered','deaths']]\n",
        "\n",
        "\n",
        "#testing data filtering\n",
        "data2=df2[(is_indonesia)][['confirmed','lat','long','recovered','deaths']]\n",
        "date=df2[(is_indonesia)][['day','confirmed']]\n",
        "\n",
        "date.day = pd.to_datetime(date.day,format='%Y%m%d', errors='ignore')\n",
        "date.set_index('day', inplace=True)\n",
        "\n",
        "n_features = 5 # this is number of parallel inputs\n",
        "n_timesteps = 100 # this is number of timesteps\n",
        "\n",
        "\n",
        "#input splitting\n",
        "X, Y = split_sequences(data.values, n_timesteps)\n",
        "\n",
        "print (X.shape,Y.shape)\n",
        "\n",
        "#normalization\n",
        "alld=np.concatenate((X,Y),1)\n",
        "alld=alld.reshape(alld.shape[0]*alld.shape[1],alld.shape[2])\n",
        "\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(alld)\n",
        "X=[scaler.transform(x) for x in X]\n",
        "y=[scaler.transform(y) for y in Y]\n",
        "\n",
        "X=np.array(X)\n",
        "y=np.array(y)[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37112 entries, 0 to 37111\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   2020-01-22   37112 non-null  object \n",
            " 1   Afghanistan  37112 non-null  object \n",
            " 2   Unnamed: 2   11398 non-null  object \n",
            " 3   33.0         37112 non-null  float64\n",
            " 4   65.0         37112 non-null  float64\n",
            " 5   0            36973 non-null  float64\n",
            " 6   0.1          35166 non-null  float64\n",
            " 7   0.2          36973 non-null  float64\n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 2.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37112 entries, 0 to 37111\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   2020-01-22   37112 non-null  object \n",
            " 1   Afghanistan  37112 non-null  object \n",
            " 2   Unnamed: 2   11398 non-null  object \n",
            " 3   33.0         37112 non-null  float64\n",
            " 4   65.0         37112 non-null  float64\n",
            " 5   0            36973 non-null  float64\n",
            " 6   0.1          35166 non-null  float64\n",
            " 7   0.2          36973 non-null  float64\n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 2.3+ MB\n",
            "(139, 70, 5) (139, 30, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLDUs3t9ZqRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training\n",
        "\n",
        "mv_net = MV_LSTM(n_features,70).cuda()\n",
        "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
        "optimizer = torch.optim.Adam(mv_net.parameters(), lr=1e-3)\n",
        "\n",
        "train_episodes = 100\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "mv_net.train()\n",
        "\n",
        "for t in range(train_episodes):\n",
        "    \n",
        "    for b in range(0,len(X),batch_size):\n",
        "       \n",
        "        p = np.random.permutation(len(X))\n",
        "        \n",
        "        inpt = X[p][b:b+batch_size,:,:]\n",
        "        target = y[p][b:b+batch_size,:]    \n",
        "        \n",
        "        x_batch = torch.tensor(inpt,dtype=torch.float32).cuda()    \n",
        "        y_batch = torch.tensor(target,dtype=torch.float32).cuda()\n",
        "       \n",
        "        mv_net.init_hidden(x_batch.size(0))\n",
        "        \n",
        "        output = mv_net(x_batch) \n",
        "        \n",
        "        \n",
        "        all_batch=torch.cat((x_batch[:,:,0], y_batch), 1)\n",
        "        \n",
        "        \n",
        "        loss = 1000*criterion(output.view(-1), all_batch.view(-1))  \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()        \n",
        "        optimizer.zero_grad() \n",
        "    print('step : ' , t , 'loss : ' , loss.item())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icd9-EMfuKP",
        "colab_type": "code",
        "outputId": "ff490108-1e77-4b9e-c78a-2a46ffbe8fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#evaluation#########################################################################################################\n",
        "#data2x=data2[~(data2.confirmed==0)]\n",
        "data2x=data2\n",
        "truth = data2\n",
        "\n",
        "data2x.values[0:len(data2x),0]=np.insert(np.diff(data2x.values[0:len(data2x),0]),0,0)\n",
        "data2x=scaler.transform(data2x) \n",
        "\n",
        "\n",
        "X_test = np.expand_dims(data2x, axis=0)\n",
        "print (X_test.shape)\n",
        "mv_net.init_hidden(1)\n",
        "\n",
        "\n",
        "lstm_out = mv_net(torch.tensor(X_test[:,-70:,:],dtype=torch.float32).cuda())\n",
        "lstm_out=lstm_out.reshape(1,100,1).cpu().data.numpy()\n",
        "\n",
        "print (data2x[-70:,0],lstm_out)\n",
        "actual_predictions = scaler.inverse_transform(np.tile(lstm_out, (1, 1,5))[0])[:,0]\n",
        "\n",
        "print (data2.values[-70:,0],actual_predictions)\n",
        "\n",
        "#actual_predictions=lstm_out\n",
        "\n",
        "\n",
        "x = np.arange(0, 54, 1)\n",
        "x2 = np.arange(0, 70, 1)\n",
        "x3 = np.arange(0, 100, 10)\n",
        "x4 = np.arange(0, 50, 1)\n",
        "\n",
        "\n",
        "#save prediction\n",
        "#with open('./lstmdata/predict_indo8.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "   # pickle.dump(pd.Series(actual_predictions), f,protocol=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 139, 5)\n",
            "[0.98193667 0.9819542  0.98193617 0.98197773 0.98193267 0.98197022\n",
            " 0.98198875 0.98200327 0.98198875 0.98204834 0.98198925 0.98204483\n",
            " 0.98207938 0.98203782 0.9820208  0.98202831 0.98206987 0.98208339\n",
            " 0.98204233 0.98204333 0.98197222 0.98206736 0.9820213  0.98205835\n",
            " 0.98209791 0.98207788 0.98201729 0.98198675 0.98208739 0.98200978\n",
            " 0.98205334 0.98209641 0.9820258  0.98205434 0.98207738 0.98212194\n",
            " 0.98206336 0.98204884 0.98204783 0.98214648 0.98207337 0.98199626\n",
            " 0.98212194 0.98222459 0.982164   0.98212495 0.98214448 0.98212445\n",
            " 0.98212795 0.98212294 0.9822266  0.9823668  0.98219705 0.98235478\n",
            " 0.98214297 0.98211944 0.98208739 0.98222309 0.98222359 0.98221908\n",
            " 0.9821585  0.9822301  0.98211343 0.98218453 0.98222209 0.98217252\n",
            " 0.9822316  0.98237681 0.98221608 0.98230371] [[[0.99997973]\n",
            "  [0.9999794 ]\n",
            "  [0.9999802 ]\n",
            "  [0.99998415]\n",
            "  [0.99998176]\n",
            "  [0.99998057]\n",
            "  [0.9999778 ]\n",
            "  [0.9999808 ]\n",
            "  [0.99998033]\n",
            "  [0.9999807 ]\n",
            "  [0.9999814 ]\n",
            "  [0.9999808 ]\n",
            "  [0.99997807]\n",
            "  [0.99998045]\n",
            "  [0.99998   ]\n",
            "  [0.9999796 ]\n",
            "  [0.99998116]\n",
            "  [0.99998   ]\n",
            "  [0.9999764 ]\n",
            "  [0.99997735]\n",
            "  [0.99997914]\n",
            "  [0.9999802 ]\n",
            "  [0.9999807 ]\n",
            "  [0.9999788 ]\n",
            "  [0.9999777 ]\n",
            "  [0.99998033]\n",
            "  [0.99998033]\n",
            "  [0.9999796 ]\n",
            "  [0.99997973]\n",
            "  [0.99997544]\n",
            "  [0.999977  ]\n",
            "  [0.99997735]\n",
            "  [0.99998105]\n",
            "  [0.99998224]\n",
            "  [0.9999802 ]\n",
            "  [0.9999776 ]\n",
            "  [0.99998045]\n",
            "  [0.99997854]\n",
            "  [0.99997985]\n",
            "  [0.99997926]\n",
            "  [0.9999801 ]\n",
            "  [0.9999801 ]\n",
            "  [0.9999771 ]\n",
            "  [0.9999789 ]\n",
            "  [0.9999809 ]\n",
            "  [0.9999808 ]\n",
            "  [0.99997926]\n",
            "  [0.9999814 ]\n",
            "  [0.999982  ]\n",
            "  [0.99998236]\n",
            "  [0.9999782 ]\n",
            "  [0.99997914]\n",
            "  [0.99997926]\n",
            "  [0.9999801 ]\n",
            "  [0.99997926]\n",
            "  [0.9999808 ]\n",
            "  [0.9999809 ]\n",
            "  [0.99997795]\n",
            "  [0.9999777 ]\n",
            "  [0.9999776 ]\n",
            "  [0.9999796 ]\n",
            "  [0.99998295]\n",
            "  [0.9999794 ]\n",
            "  [0.9999813 ]\n",
            "  [0.99998164]\n",
            "  [0.9999813 ]\n",
            "  [0.99998116]\n",
            "  [0.9999809 ]\n",
            "  [0.9999788 ]\n",
            "  [0.99997747]\n",
            "  [0.9999807 ]\n",
            "  [0.99998033]\n",
            "  [0.99997914]\n",
            "  [0.9999813 ]\n",
            "  [0.9999802 ]\n",
            "  [0.9999809 ]\n",
            "  [0.99998176]\n",
            "  [0.9999789 ]\n",
            "  [0.99998236]\n",
            "  [0.99997866]\n",
            "  [0.99998045]\n",
            "  [0.99997973]\n",
            "  [0.9999821 ]\n",
            "  [0.99997854]\n",
            "  [0.9999794 ]\n",
            "  [0.9999765 ]\n",
            "  [0.9999815 ]\n",
            "  [0.99998105]\n",
            "  [0.9999808 ]\n",
            "  [0.99998057]\n",
            "  [0.999982  ]\n",
            "  [0.9999765 ]\n",
            "  [0.99997854]\n",
            "  [0.9999802 ]\n",
            "  [0.9999801 ]\n",
            "  [0.99997663]\n",
            "  [0.9999802 ]\n",
            "  [0.9999801 ]\n",
            "  [0.99997973]\n",
            "  [0.9999777 ]]]\n",
            "[114. 149. 113. 196. 106. 181. 218. 247. 218. 337. 219. 330. 399. 316.\n",
            " 282. 297. 380. 407. 325. 327. 185. 375. 283. 357. 436. 396. 275. 214.\n",
            " 415. 260. 347. 433. 292. 349. 395. 484. 367. 338. 336. 533. 387. 233.\n",
            " 484. 689. 568. 490. 529. 489. 496. 486. 693. 973. 634. 949. 526. 479.\n",
            " 415. 686. 687. 678. 557. 700. 467. 609. 684. 585. 703. 993. 672. 847.] [36147.527 36146.812 36148.48  36156.336 36151.574 36149.19  36143.72\n",
            " 36149.668 36148.72  36149.43  36150.86  36149.668 36144.195 36148.957\n",
            " 36148.004 36147.29  36150.383 36148.004 36140.86  36142.766 36146.336\n",
            " 36148.48  36149.43  36145.62  36143.48  36148.72  36148.72  36147.29\n",
            " 36147.527 36138.957 36142.05  36142.766 36150.145 36152.527 36148.48\n",
            " 36143.242 36148.957 36145.145 36147.766 36146.574 36148.242 36148.242\n",
            " 36142.29  36145.86  36149.906 36149.668 36146.574 36150.86  36152.05\n",
            " 36152.766 36144.434 36146.336 36146.574 36148.242 36146.574 36149.668\n",
            " 36149.906 36143.957 36143.48  36143.242 36147.29  36153.953 36146.812\n",
            " 36150.62  36151.336 36150.62  36150.383 36149.906 36145.62  36143.004\n",
            " 36149.43  36148.72  36146.336 36150.62  36148.48  36149.906 36151.574\n",
            " 36145.86  36152.766 36145.383 36148.957 36147.527 36152.29  36145.145\n",
            " 36146.812 36141.098 36151.098 36150.145 36149.668 36149.19  36152.05\n",
            " 36141.098 36145.145 36148.48  36148.242 36141.336 36148.48  36148.242\n",
            " 36147.527 36143.48 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR49RN0YiUke",
        "colab_type": "code",
        "outputId": "3ed8b456-b626-4ef3-872b-d49f42d16ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "#visualization  \n",
        "fig, ax = plt.subplots() \n",
        "plt.title('Days vs Confirmed Cases Accumulation')\n",
        "plt.ylabel('Confirmed')\n",
        "\n",
        "left, width = .25, .5\n",
        "bottom, height = .25, .5\n",
        "right = left + width\n",
        "top = bottom + height\n",
        "\n",
        "print (date.index)\n",
        "date_list=pd.date_range(start=date.index[0],end=date.index[-1])\n",
        "print (date_list)\n",
        "\n",
        "plt.axvline(x=np.array(date_list)[66], color='r', linestyle='--')\n",
        "\n",
        "ax.text(0.2*(left+right), 0.8*(bottom+top), 'input sequence',\n",
        "        horizontalalignment='left',\n",
        "        verticalalignment='center',\n",
        "        fontsize=10, color='red',\n",
        "        transform=ax.transAxes)\n",
        "ax.text(0.0125*(left+right), 0.77*(bottom+top), '______________________',\n",
        "        horizontalalignment='left',\n",
        "        verticalalignment='center',\n",
        "        fontsize=20, color='red',\n",
        "        transform=ax.transAxes)\n",
        "\n",
        "\n",
        "\n",
        "sumpred=np.cumsum(np.absolute(actual_predictions))\n",
        "\n",
        "print (date.values.shape)  \n",
        "print (sqrt(mean_squared_error(date.confirmed,sumpred)))          \n",
        "#plt.plot(date.values[-67:],np.cumsum(data2.confirmed.values[-67:]))\n",
        "plt.plot(np.array(date_list),sumpred,label='Prediction')\n",
        "plt.plot(np.array(date_list),date.confirmed,label='Actual')\n",
        "plt.xticks(rotation=90)\n",
        "fig.autofmt_xdate()\n",
        "plt.legend(loc=2)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26',\n",
            "       '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31',\n",
            "       ...\n",
            "       '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03',\n",
            "       '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08'],\n",
            "      dtype='object', name='day', length=139)\n",
            "DatetimeIndex(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25',\n",
            "               '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29',\n",
            "               '2020-01-30', '2020-01-31',\n",
            "               ...\n",
            "               '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02',\n",
            "               '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06',\n",
            "               '2020-06-07', '2020-06-08'],\n",
            "              dtype='datetime64[ns]', length=139, freq='D')\n",
            "(139, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6666f7f4bffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfirmed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msumpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#plt.plot(date.values[-67:],np.cumsum(data2.confirmed.values[-67:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msumpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [139, 100]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOW4ouGQnnBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}